{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4af177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Model Performance Visualization\n",
    "\n",
    "# This notebook generates the visualization figures for the paper \"Supervised Error Detection Using Machine Learning\", comparing different classifier performance across various datasets.\n",
    "# 1. Setup and Imports\n",
    "# 2. Utility Functions\n",
    "# 3. Binary Classification Visualization\n",
    "# 4. Multiclass Classification Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 1. Setup and Imports\n",
    "\n",
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set global plot parameters for a consistent look\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "plt.rcParams[\"axes.labelsize\"] = 10\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 9\n",
    "plt.rcParams[\"ytick.labelsize\"] = 9\n",
    "\n",
    "# Set the mapping for model names to ensure consistent labeling\n",
    "MODEL_MAPPING_BINARY = {\n",
    "    \"DummyClassifier\": \"Random\",\n",
    "    \"RandomForestClassifier\": \"Random Forest\",\n",
    "    \"SVC\": \"SVM-Classifier\",\n",
    "    \"TimeSeriesForestClassifier\": \"TS-Forest\",\n",
    "    \"ROCKET\": \"ROCKET\",\n",
    "}\n",
    "\n",
    "MODEL_MAPPING_MULTICLASS = {\n",
    "    \"DummyClassifier\": \"Baseline\",\n",
    "    \"RandomForestClassifier\": \"Random Forest\",\n",
    "    \"SVC\": \"SVM\",\n",
    "    \"TimeSeriesForestClassifier\": \"TS Forest\",\n",
    "    \"ROCKET\": \"ROCKET\",\n",
    "}\n",
    "\n",
    "# Set the order of models for visualization\n",
    "MODEL_ORDER_BINARY = [\n",
    "    \"Random\",\n",
    "    \"SVM-Classifier\",\n",
    "    \"Random Forest\",\n",
    "    \"TS-Forest\",\n",
    "    \"ROCKET\",\n",
    "]\n",
    "MODEL_ORDER_MULTICLASS = [\"Baseline\", \"SVM\", \"Random Forest\", \"TS Forest\", \"ROCKET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f385cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4. Utility Functions\n",
    "# This section contains the visualization functions used to generate the plots.\n",
    "\n",
    "\n",
    "def plot_results_as_matrix(\n",
    "    df,\n",
    "    plot_title,\n",
    "    metric=\"f1_score\",\n",
    "    figsize=(15, 5),\n",
    "    font_size=10,\n",
    "    cmap=\"YlGnBu\",\n",
    "    model_name_mapping=None,\n",
    "    model_order=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a heatmap visualization of model performance across different datasets.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing results with at least 'dataset', 'model', and performance metrics\n",
    "    plot_title : str\n",
    "        Title to be displayed on the plot\n",
    "    metric : str, default='f1_score'\n",
    "        The metric to visualize (must be a column in df)\n",
    "    figsize : tuple, default=(15, 5)\n",
    "        Figure size as (width, height)\n",
    "    font_size : int, default=10\n",
    "        Base font size for labels and annotations\n",
    "    cmap : str, default=\"YlGnBu\"\n",
    "        Colormap for the heatmap\n",
    "    model_name_mapping : dict, default=None\n",
    "        Dictionary mapping original model names to display names\n",
    "    model_order : list, default=None\n",
    "        List defining the order of models on the y-axis (from top to bottom)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : tuple\n",
    "        The figure and axis objects from matplotlib\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    required_cols = [\"dataset\", \"model\", metric]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Required column '{col}' not found in DataFrame\")\n",
    "\n",
    "    # Extract dataset name without the full prefix for cleaner labels\n",
    "    df = df.copy()  # Make a copy to avoid modifying the original\n",
    "\n",
    "    # Extract a more readable dataset name using the last part after underscore\n",
    "    df[\"dataset_name\"] = (\n",
    "        df[\"dataset\"]\n",
    "        .str.split(\"_\")\n",
    "        .apply(lambda x: \"_\".join(x[3:]) if len(x) > 3 else x[-1])\n",
    "    )\n",
    "\n",
    "    # Apply model name mapping if provided\n",
    "    if model_name_mapping:\n",
    "        df[\"model_display_name\"] = df[\"model\"].map(\n",
    "            lambda x: model_name_mapping.get(x, x)\n",
    "        )\n",
    "    else:\n",
    "        df[\"model_display_name\"] = df[\"model\"]\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot_df = df.pivot(\n",
    "        index=\"model_display_name\", columns=\"dataset_name\", values=metric\n",
    "    )\n",
    "\n",
    "    # Reorder the index based on model_order if provided\n",
    "    if model_order:\n",
    "        # Verify all models in model_order exist in the pivot_df\n",
    "        missing_models = [model for model in model_order if model not in pivot_df.index]\n",
    "        if missing_models:\n",
    "            print(\n",
    "                f\"Warning: The following models in model_order were not found: {missing_models}\"\n",
    "            )\n",
    "\n",
    "        # Get valid models that exist in both model_order and pivot_df.index\n",
    "        valid_models = [model for model in model_order if model in pivot_df.index]\n",
    "\n",
    "        # Get models in pivot_df.index that aren't in model_order (to append at the end if needed)\n",
    "        remaining_models = [\n",
    "            model for model in pivot_df.index if model not in model_order\n",
    "        ]\n",
    "\n",
    "        # Reorder with specified order first, then any remaining models\n",
    "        new_order = valid_models + remaining_models\n",
    "        pivot_df = pivot_df.reindex(new_order)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        pivot_df,\n",
    "        cmap=cmap,\n",
    "        annot=True,  # Show values in cells\n",
    "        fmt=\".2f\",  # Format to 2 decimal places\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"label\": metric.replace(\"_\", \" \").title()},\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # Style the plot\n",
    "    ax.set_title(\n",
    "        f'{metric.replace(\"_\", \" \").title()} by Model and Dataset for \"{plot_title}\"',\n",
    "        fontsize=font_size + 2,\n",
    "    )\n",
    "    ax.set_xlabel(\"Dataset\", fontsize=font_size + 2)\n",
    "    ax.set_ylabel(\"Model\", fontsize=font_size + 2)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=font_size)\n",
    "\n",
    "    # Rotate x-axis labels if needed\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # Adjust layout to make sure everything fits\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644aa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def plot_combined_results(\n",
    "    df_list,\n",
    "    metric=\"f1_score\",\n",
    "    figsize=(8, 5),\n",
    "    font_size=10,\n",
    "    cmap=\"YlGnBu\",\n",
    "    model_name_mapping=None,\n",
    "    model_order=None,\n",
    "    title=None,\n",
    "    add_gap=True,\n",
    "    remove_prefix=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a heatmap visualization combining multiple result dataframes with gap columns.\n",
    "    Uses a simple approach by combining pivoted dataframes side by side.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_list : list of pandas.DataFrame or single pandas.DataFrame\n",
    "        DataFrames containing results with at least 'dataset', 'model', and performance metrics\n",
    "    metric : str, default='f1_score'\n",
    "        The metric to visualize (must be a column in df)\n",
    "    figsize : tuple, default=(8, 5)\n",
    "        Figure size as (width, height)\n",
    "    font_size : int, default=10\n",
    "        Base font size for labels and annotations\n",
    "    cmap : str, default=\"YlGnBu\"\n",
    "        Colormap for the heatmap\n",
    "    model_name_mapping : dict, default=None\n",
    "        Dictionary mapping original model names to display names\n",
    "    model_order : list, default=None\n",
    "        List defining the order of models on the y-axis (from top to bottom)\n",
    "    title : str, default=None\n",
    "        Title for the figure. If None, a default title will be created.\n",
    "    add_gap : bool, default=True\n",
    "        Whether to add gap columns between different dataframes\n",
    "    remove_prefix : str, default=None\n",
    "        Prefix to remove from dataset names, e.g., \"multiclass_\"\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : tuple\n",
    "        The figure and axis objects from matplotlib\n",
    "    \"\"\"\n",
    "    # Convert to list if a single DataFrame is passed\n",
    "    if isinstance(df_list, pd.DataFrame):\n",
    "        df_list = [df_list]\n",
    "\n",
    "    # Process each dataframe to get pivoted versions\n",
    "    pivoted_dfs = []\n",
    "\n",
    "    for df_idx, df in enumerate(df_list):\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply model name mapping if provided\n",
    "        if model_name_mapping:\n",
    "            df_copy[\"model_display_name\"] = df_copy[\"model\"].map(\n",
    "                lambda x: model_name_mapping.get(x, x)\n",
    "            )\n",
    "        else:\n",
    "            df_copy[\"model_display_name\"] = df_copy[\"model\"]\n",
    "\n",
    "        # Remove prefix from dataset names if specified\n",
    "        if remove_prefix and isinstance(remove_prefix, str):\n",
    "            df_copy[\"dataset_display_name\"] = df_copy[\"dataset\"].apply(\n",
    "                lambda x: (\n",
    "                    x.replace(remove_prefix, \"\")\n",
    "                    if isinstance(x, str) and x.startswith(remove_prefix)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            df_copy[\"dataset_display_name\"] = df_copy[\"dataset\"]\n",
    "\n",
    "        # Create pivot table with cleaned dataset names\n",
    "        pivot_df = df_copy.pivot(\n",
    "            index=\"model_display_name\", columns=\"dataset_display_name\", values=metric\n",
    "        )\n",
    "\n",
    "        # Add to list of pivoted dataframes\n",
    "        pivoted_dfs.append(pivot_df)\n",
    "\n",
    "    # Combine all pivoted dataframes side by side with gaps if requested\n",
    "    combined_df = None\n",
    "\n",
    "    for i, pivot_df in enumerate(pivoted_dfs):\n",
    "        if combined_df is None:\n",
    "            combined_df = pivot_df.copy()\n",
    "        else:\n",
    "            # Add a gap column if requested\n",
    "            if add_gap:\n",
    "                # Create gap column with NaN values\n",
    "                gap_name = f\"_gap_{i}\"\n",
    "                combined_df[gap_name] = np.nan\n",
    "\n",
    "            # Add the next dataframe's columns\n",
    "            for col in pivot_df.columns:\n",
    "                combined_df[col] = pivot_df[col]\n",
    "\n",
    "    # Reorder the index based on model_order if provided\n",
    "    if model_order:\n",
    "        # Get valid models that exist in both model_order and combined_df.index\n",
    "        valid_models = [model for model in model_order if model in combined_df.index]\n",
    "\n",
    "        # Get models in combined_df.index that aren't in model_order (to append at the end)\n",
    "        remaining_models = [\n",
    "            model for model in combined_df.index if model not in model_order\n",
    "        ]\n",
    "\n",
    "        # Reorder with specified order first, then any remaining models\n",
    "        new_order = valid_models + remaining_models\n",
    "        combined_df = combined_df.reindex(new_order)\n",
    "\n",
    "    # Sort columns alphabetically within each group, keeping gap columns in place\n",
    "    if add_gap:\n",
    "        # Identify gap columns\n",
    "        gap_cols = [\n",
    "            col\n",
    "            for col in combined_df.columns\n",
    "            if isinstance(col, str) and col.startswith(\"_gap_\")\n",
    "        ]\n",
    "\n",
    "        # Group columns by their position relative to gap columns\n",
    "        grouped_cols = []\n",
    "        current_group = []\n",
    "\n",
    "        for col in combined_df.columns:\n",
    "            if col in gap_cols:\n",
    "                if current_group:\n",
    "                    grouped_cols.append(sorted(current_group))\n",
    "                grouped_cols.append([col])\n",
    "                current_group = []\n",
    "            else:\n",
    "                current_group.append(col)\n",
    "\n",
    "        if current_group:\n",
    "            grouped_cols.append(sorted(current_group))\n",
    "\n",
    "        # Flatten the grouped columns\n",
    "        sorted_cols = []\n",
    "        for group in grouped_cols:\n",
    "            sorted_cols.extend(group)\n",
    "\n",
    "        # Reorder columns\n",
    "        combined_df = combined_df[sorted_cols]\n",
    "\n",
    "    # Create figure and plot - explicitly set figsize to ensure it takes effect\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Create a mask to hide the gap columns in the heatmap\n",
    "    if add_gap:\n",
    "        mask = pd.DataFrame(False, index=combined_df.index, columns=combined_df.columns)\n",
    "        for col in combined_df.columns:\n",
    "            if isinstance(col, str) and col.startswith(\"_gap_\"):\n",
    "                mask[col] = True\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    # Create heatmap\n",
    "    cbar_kws = {\"label\": metric.replace(\"_\", \" \").title()}\n",
    "\n",
    "    # Create the heatmap with all the settings\n",
    "    sns.heatmap(\n",
    "        combined_df,\n",
    "        cmap=cmap,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        cbar_kws=cbar_kws,\n",
    "        ax=ax,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "    # Set title\n",
    "    if title is None:\n",
    "        title = f'{metric.replace(\"_\", \" \").title()} by Model and Dataset'\n",
    "    ax.set_title(title, fontsize=font_size + 2)\n",
    "\n",
    "    # Style the plot\n",
    "    ax.set_xlabel(\"Dataset\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"Model\", fontsize=font_size)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=font_size)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # FIX: Only hide gap columns without disrupting other labels\n",
    "    if add_gap:\n",
    "        # Get all the current tick positions and labels\n",
    "        positions = np.arange(len(combined_df.columns)) + 0.5\n",
    "        labels = list(combined_df.columns)\n",
    "\n",
    "        # Create lists for non-gap positions and labels\n",
    "        non_gap_positions = []\n",
    "        non_gap_labels = []\n",
    "\n",
    "        # Filter out gap columns\n",
    "        for i, (pos, label) in enumerate(zip(positions, labels)):\n",
    "            if not (isinstance(label, str) and label.startswith(\"_gap_\")):\n",
    "                non_gap_positions.append(pos)\n",
    "                non_gap_labels.append(label)\n",
    "\n",
    "        # Set the positions and labels\n",
    "        ax.set_xticks(non_gap_positions)\n",
    "        ax.set_xticklabels(non_gap_labels, rotation=45, ha=\"right\")\n",
    "\n",
    "    # Adjust layout to make sure everything fits\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2. Binary Classification Visualization\n",
    "# This section generates visualizations for the binary classification experiments,\n",
    "# comparing different models on anomaly detection tasks.\n",
    "\n",
    "# Load binary classification results\n",
    "df_binary_vs_ref = pd.read_csv(\"../results/s04/binary_vs_ref/results.csv\")\n",
    "\n",
    "# Generate visualization for binary classification against reference observations\n",
    "title_ref = \"Binary Classification vs Reference Normal Observations (#OK=50)\"\n",
    "fig_ref, ax_ref = plot_results_as_matrix(\n",
    "    df_binary_vs_ref,\n",
    "    title_ref,\n",
    "    metric=\"f1_score\",\n",
    "    model_name_mapping=MODEL_MAPPING_BINARY,\n",
    "    model_order=MODEL_ORDER_BINARY,\n",
    "    figsize=(15, 5),\n",
    ")\n",
    "plt.savefig(\"matrix_binary_vs_ref.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Load binary classification results (all observations)\n",
    "df_binary_vs_all = pd.read_csv(\"../results/s04/binary_vs_all/results.csv\")\n",
    "\n",
    "# Generate visualization for binary classification against all normal observations\n",
    "title_all = \"Binary Classification vs All Normal Observations (#OK=1215)\"\n",
    "fig_all, ax_all = plot_results_as_matrix(\n",
    "    df_binary_vs_all,\n",
    "    title_all,\n",
    "    metric=\"f1_score\",\n",
    "    model_name_mapping=MODEL_MAPPING_BINARY,\n",
    "    model_order=MODEL_ORDER_BINARY,\n",
    "    figsize=(15, 5),\n",
    ")\n",
    "plt.savefig(\"matrix_binary_vs_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# %% 3. Multiclass Classification Visualization\n",
    "# This section generates visualizations for the multiclass classification experiments,\n",
    "# comparing model performance across different error group classifications.\n",
    "\n",
    "# Load multiclass classification results\n",
    "df_groups = pd.read_csv(\"../results/s04/multiclass_with_groups/results.csv\")\n",
    "df_all = pd.read_csv(\"../results/s04/multiclass_with_all/results.csv\")\n",
    "\n",
    "# Generate visualization for multiclass classification\n",
    "fig_multi, ax_multi = plot_combined_results(\n",
    "    [df_groups, df_all],\n",
    "    metric=\"f1_score\",\n",
    "    model_name_mapping=MODEL_MAPPING_MULTICLASS,\n",
    "    model_order=MODEL_ORDER_MULTICLASS,\n",
    "    title=\"F1-Score by Model and Dataset for Multiclass Classification\",\n",
    "    figsize=(8, 5),\n",
    "    remove_prefix=\"multiclass_\",\n",
    ")\n",
    "plt.savefig(\"multiclass_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm_path,\n",
    "    figsize=(12, 10),\n",
    "    font_size=10,\n",
    "    cmap=\"YlGnBu\",\n",
    "    normalize=True,\n",
    "    title=None,\n",
    "    class_names=None,\n",
    "    save_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using a similar style to the other visualizations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cm_path : str\n",
    "        Path to the CSV file containing the confusion matrix\n",
    "    figsize : tuple, default=(12, 10)\n",
    "        Figure size as (width, height)\n",
    "    font_size : int, default=10\n",
    "        Base font size for labels and annotations\n",
    "    cmap : str, default=\"YlGnBu\"\n",
    "        Colormap for the heatmap\n",
    "    normalize : bool, default=True\n",
    "        Whether to normalize the confusion matrix by row (true labels)\n",
    "    title : str, default=None\n",
    "        Title for the figure. If None, a default title will be created.\n",
    "    class_names : list, default=None\n",
    "        List of class names to use as labels. If None, uses indices.\n",
    "    save_path : str, default=None\n",
    "        Path to save the figure. If None, the figure is not saved.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : tuple\n",
    "        The figure and axis objects from matplotlib\n",
    "    \"\"\"\n",
    "    # Load the confusion matrix from CSV\n",
    "    cm = pd.read_csv(cm_path, header=0, index_col=None).values\n",
    "\n",
    "    # Create class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"{i}\" for i in range(cm.shape[0])]\n",
    "\n",
    "    # Create figure with specified font\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Normalize the confusion matrix if requested\n",
    "    if normalize:\n",
    "        # Avoid division by zero\n",
    "        row_sums = cm.sum(axis=1)\n",
    "        # Replace zeros with ones to avoid division by zero\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        cm_normalized = cm / row_sums[:, np.newaxis]\n",
    "\n",
    "        # Create heatmap with normalized values\n",
    "        sns.heatmap(\n",
    "            cm_normalized,\n",
    "            annot=cm,  # Show original counts as annotations\n",
    "            fmt=\"d\",  # Format as integers\n",
    "            cmap=cmap,\n",
    "            linewidths=0.5,\n",
    "            square=True,\n",
    "            cbar_kws={\"label\": \"Normalized Frequency\"},\n",
    "            ax=ax,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "        )\n",
    "    else:\n",
    "        # Create heatmap with raw counts\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",  # Format as integers\n",
    "            cmap=cmap,\n",
    "            linewidths=0.5,\n",
    "            square=True,\n",
    "            cbar_kws={\"label\": \"Count\"},\n",
    "            ax=ax,\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "        )\n",
    "\n",
    "    # Set title\n",
    "    if title is None:\n",
    "        title = \"Confusion Matrix\"\n",
    "    ax.set_title(title, fontsize=font_size + 4)\n",
    "\n",
    "    # Style the plot\n",
    "    ax.set_xlabel(\"Predicted Label\", fontsize=font_size + 2)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=font_size + 2)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=font_size)\n",
    "\n",
    "    # Adjust the layout for better display of all elements\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure if a path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Example usage\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    cm_path=\"results/multiclass_with_all/multiclass_all_errors_ROCKET_cm.csv\",\n",
    "    figsize=(12, 10),\n",
    "    normalize=True,  # Normalize by row (true labels)\n",
    "    title=\"Confusion Matrix: ROCKET Model on Multiclass All Errors\",\n",
    "    save_path=\"confusion_matrix_rocket.png\",\n",
    ")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
